unit NeuralNetwork;

interface

{$I NNConfig.inc}

uses
  WinAPI.Windows,
  System.Types, System.Classes, System.SysUtils,
  NNCommon, mt19937;

type
  TNeuralNetwork = class;
  TNNLayer = class;

  TNNOptimizerClass = class of TNNOptimizer;
  TNNOptimizer = class
  protected
    FType: TNNOptimizerType; // Тип оптимизатора
    FName: String; // Имя оптимизатора
    FLearningRate: NNFloat; // Скорость обучения
    FLayer: TNNLayer;
    FUpdate: TNNProcess;
  public
    constructor Create; overload; virtual;
    constructor Create( const AOptimizerOptimizerType: TNNOptimizerType; ALearningRate: NNFloat ); overload;
    procedure Init; virtual;
    property OptName: String read FName;
    property OptType: TNNOptimizerType read FType;
    property LearningRate: NNFloat read FLearningRate write FLearningRate;
    property Update: TNNProcess read FUpdate;
  end;

  TNNLossesClass = class of TNNLossFunction;
  TNNLossFunction = class
  protected
    FType: TNNLosses;
    FName: String;
    FMeanValue: NNFloat;
  public
    constructor Create; overload; virtual;
    constructor Create( const ALossFunctionType: TNNLosses ); overload;
    procedure Init; virtual;
    property FuncName: String read FName;
    property FuncType: TNNLosses read FType;
    property MeanValue: NNFloat read FMeanValue;
    function ForwardPass( AYTrue, AYPred: PNNFloat; ACount: int32 ): NNFloat; virtual; abstract;
    procedure BackwardPass( AYTrue, AYPred: PNNFloat; ACount: int32; AGradients: PNNFloat ); virtual; abstract;
  end;

  TNNLayer = class
  protected
    FNeuralNetwork: TNeuralNetwork;
    FIndex: int32;

    FInputsCount, FInputsCount1: int32;
    FOutputsCount, FOutputsCount1: int32;
    FWeightsCount, FWeightsCount1: int32;
    FBiasesCount, FBiasesCount1: int32;

    FOutputs: TNNDynArray;
    FWeights: TNNDynArray;
    FBiases: TNNDynArray;
    FOutGrads, FWghtsGrads, FBsGrads: TNNDynArray;

    FInputData: PNNFloat;
    FInputGrads: PNNFloat;
    FWeight: PNNFloat;
    FBias: PNNFloat;
    FOutputGrads, FWeightsGrads, FBiasesGrads: PNNFloat;
    FOutput: PNNFloat;

    FActivationMethod: TNNActivationMethod;
    FOptimizer: TNNOptimizer;

    FUseBiases: boolean;
    FForward: TNNForwardProcess;
    FBackward: TNNBackwardProcess;
    FInitWeights: TNNProcess;
    FInitBiases: TNNProcess;
    FLayerType: TNNLayerType;

    procedure EmptyProcess;
    {function GetBiases: PNNDynArray; inline;
    function GetWeights: PNNDynArray; inline;}
  public
    class function CreateFromStream( const ANeuralNetwork: TObject; const AStream: TStream ): TNNLayer;
    procedure LoadFromStream( const AStream: TStream ); virtual; abstract;
    procedure SaveToStream( const AStream: TStream ); virtual; abstract;
    constructor Create; virtual;
    property LayerType: TNNLayerType read FLayerType;
    property NeuralNetwork: TNeuralNetwork read FNeuralNetwork write FNeuralNetwork;

    procedure Build( AIsTraining: boolean = false ); virtual; abstract;

    property UseBiases: boolean read FUseBiases write FUseBiases;

    property ActivationMethod: TNNActivationMethod read FActivationMethod write FActivationMethod;

    property InputsCount: int32 read FInputsCount;
    property OutputsCount: int32 read FOutputsCount write FOutputsCount;
    property Output: PNNFloat read FOutput;
    property WeightsCount: int32 read FWeightsCount;
    property Weights: PNNFloat read FWeight;
    property BiasesCount: int32 read FBiasesCount;
    property Biases: PNNFloat read FBias;
    property InputGrads: PNNFloat read FInputGrads;
    property OutputGrads: PNNFloat read FOutputGrads;
    property WeightGrads: PNNFLoat read FWeightGrads;
    property BiasGrads: PNNFLoat read FBiasGrads;



    property InitWeights: TNNProcess read FInitWeights;
    property InitBiases: TNNProcess read FInitBiases;

    property ForwardPropagation: TNNForwardProcess read FForward;
    property BackwardPropagation: TNNBackwardProcess read FBackward;

    {property Output: PNNDynArray read GetOutput;
    property Weights: PNNDynArray read GetWeights;
    property Biases: PNNDynArray read GetBiases;
    property BackwardPropagation: TNNProcess read FBackwardPropagation;}
  end;

  TNNMT19937 = packed record
    _useInInit, _useInProcess, _randomize: boolean;
    seed: UInt32;
  end;

  TNNGetTrainDataProc = procedure ( ANeuralNetwork: TNeuralNetwork; AEpoch, ASequence: int32; var AData, AYTrue: PNNFLoat ) of Object;
  TNNTrainResultProc = procedure ( ANeuralNetwork: TNeuralNetwork; AEpoch, ASequence: int32; AMeanLossValue: NNFloat ) of Object;
  TNeuralNetwork = class
  private
    FMT19937: TMT19937;
    FLayers: array of TNNLayer;
    FOutput: PNNFloat;
    FLayersCount, FLayersCount1, FLayersCount2: int32;
    FLossFunction: TNNLossFunction;
    FLossGrads: TNNDynArray;
    FInputsCount: int32;
    FOutputsCount: int32;
    FOptimizer: TNNOptimizerType;
    function GetLossFunction: TNNLosses;
    procedure SetLossFunction(const Value: TNNLosses);
    function GetLayer(AIndex: int32): TNNLayer;
  public
    MT19937Params: TNNMT19937;

    procedure LoadFromStream( const AStream: TStream );
    procedure SaveToStream( const AStream: TStream );
    procedure LoadFromFile( const AFileName: TFileName );
    procedure SaveToFile( const AFileName: TFileName );

    constructor Create;
    destructor Destroy; override;
    property InputsCount: int32 read FInputsCount write FInputsCount;
    property Output: PNNFloat read FOutput;
    property OutputsCount: int32 read FOutputsCount;
    procedure AddLayer( const ALayer: TNNLayer );
    property Layers[ AIndex: int32 ]: TNNLayer read GetLayer;
    property LayersCount: int32 read FLayersCount;
    property LossFunction: TNNLosses read GetLossFunction write SetLossFunction;
    property Optimizer: TNNOptimizerType read FOptimizer write FOptimizer;
    procedure Build( AIsTraining: boolean = false );
    procedure Clear;

    procedure Initialize;
    procedure ForwardPropagation( const AData: PNNFloat );
    procedure BackwardPropagation( const AData, AYTrue: PNNFloat );

    procedure Train( AEpochs, ASequences: int32; AGetDataProc: TNNGetTrainDataProc; AResultProc: TNNTrainResultProc );

    function MT19937_Normal( _mu, _sigma: NNFloat ): NNFloat; inline;
    function MT19937_Uniform( _offset, _range: NNFloat ): NNFloat; inline;
  end;

implementation

uses NNLosses, NNFullyConnectedLayer;

{ TNeuralNetwork }

procedure TNeuralNetwork.AddLayer(const ALayer: TNNLayer);
var
  n: int32;
begin
  n := Length( FLayers );
  SetLength( FLayers, n + 1 );
  FLayers[ n ] := ALayer;
  ALayer.FNeuralNetwork := Self;
  ALayer.FIndex := n;
  FOutputsCount := ALayer.FOutputsCount;
  FLayersCount := Length( FLayers );
  FLayersCount1 := FLayersCount - 1;
  FLayersCount2 := FLayersCount - 2;
end;

procedure TNeuralNetwork.BackwardPropagation(const AData, AYTrue: PNNFloat);
var
  i: int32;
begin
  FLayers[ 0 ].FInputData := AData;
  FLayers[ 0 ].ForwardPropagation( AData );
  for I := 1 to FLayersCount1 do begin
    FLayers[ i ].FInputData := FLayers[ i - 1 ].FOutput;
    FLayers[ i ].ForwardPropagation( FLayers[ i - 1 ].FOutput );
  end;

  FLossFunction.ForwardPass( AYTrue, FOutput, FOutputsCount );
  FLossFunction.BackwardPass( AYTrue, FOutput, FOutputsCount, @FLossGrads[ 0 ] );

  FLayers[ FLayersCount1 ].BackwardPropagation( @FLossGrads[ 0 ] );
  for I := FLayersCount2 to 0 do
    FLayers[ i ].BackwardPropagation( FLayers[ i - 1 ].Gradients );
end;

procedure TNeuralNetwork.Build( AIsTraining: boolean );
var
  i: int32;
begin
  MT19937Params._useInInit := false;
  MT19937Params._useInProcess := false;

  for I := 0 to FLayersCount1 do FLayers[ i ].Build( AIsTraining );

  FOutputsCount := FLayers[ FLayersCount1 ].FOutputsCount;
  FOutput := FLayers[ FLayersCount1 ].Output;
  SetLength( FLossGrads, FOutputsCount );
end;

procedure TNeuralNetwork.Clear;
var
  i: int32;
begin
  for I := 0 to FLayersCount1 do FLayers[ i ].Free;
  SetLength( FLayers, 0 );
  FLayersCount := 0;
  FLayersCount1 := -1;
end;

constructor TNeuralNetwork.Create;
begin
  MT19937Params._randomize := true;
  FMT19937 := TMT19937.Create;
  SetLossFunction( lfMSE );
end;

destructor TNeuralNetwork.Destroy;
begin
  Clear;
  FLossFunction.Free;
  FMT19937.Free;
  inherited;
end;

procedure TNeuralNetwork.ForwardPropagation(const AData: PNNFloat);
var
  i: int32;
begin
  FLayers[ 0 ].ForwardPropagation( AData );
  for I := 1 to FLayersCount1 do
    FLayers[ i ].ForwardPropagation( FLayers[ i - 1 ].FOutput );
end;

function TNeuralNetwork.GetLayer(AIndex: int32): TNNLayer;
begin
  Result := FLayers[ AIndex ];
end;

function TNeuralNetwork.GetLossFunction: TNNLosses;
begin
  Result := FLossFunction.FType;
end;

procedure TNeuralNetwork.Initialize;
var
  i: int32;
  i64: int64;
begin
  if MT19937Params._useInInit then begin
    if MT19937Params._randomize then begin
      if not QueryPerformanceCounter( i64 ) then i64 := GetTickCount;
      FMT19937.Seed := ( UInt64( Random( MAXINT ) ) shl 32 ) xor UInt64( i64 );
    end else
      FMT19937.Seed := MT19937Params.seed;
    FMT19937.Init;
  end;

  for I := 0 to FLayersCount1 do begin
    FLayers[ i ].InitWeights;
    FLayers[ i ].InitBiases;
  end;
end;

procedure TNeuralNetwork.LoadFromFile(const AFileName: TFileName);
var
  Stream: TStream;
begin
  Stream := TFileStream.Create( AFileName, fmOpenRead or fmShareDenyWrite );
  try
    Stream.Position := 0;
    LoadFromStream( Stream );
  finally
    Stream.Free;
  end;
end;

procedure TNeuralNetwork.LoadFromStream(const AStream: TStream);
var
  i, n: int32;
begin
  Clear;

  // Load params

  // Load layers
  MT19937Params._useInInit := false;
  MT19937Params._useInProcess := false;

  AStream.Read( n, 4 );
  for I := 0 to n - 1 do
    AddLayer( TNNLayer.CreateFromStream( Self, AStream ) );

  FOutput := FLayers[ FLayersCount1 ].Output;
end;

function TNeuralNetwork.MT19937_Normal( _mu, _sigma: NNFloat ): NNFloat;
begin
  {$IFDEF NNFLOAT_SINGLE}
    Result := FMT19937.NormalGaussSingle( _mu, _sigma );
  {$ELSE IFDEF NNFLOAT_DOUBLE}
    Result := FMT19937.NormalGaussDouble( _mu, _sigma );
  {$ELSE}
    Result := FMT19937.NormalGaussExtended( _mu, _sigma );
  {$ENDIF}
end;

function TNeuralNetwork.MT19937_Uniform( _offset, _range: NNFloat ): NNFloat;
begin
  {$IFDEF NNFLOAT_SINGLE}
    Result := FMT19937.UniformSingle( _offset, _range );
  {$ELSE IFDEF NNFLOAT_DOUBLE}
    Result := FMT19937.UniformDouble( _offset, _range );
  {$ELSE}
    Result := FMT19937.UniformExtended( _offset, _range );
  {$ENDIF}
end;

procedure TNeuralNetwork.SaveToFile(const AFileName: TFileName);
var
  Stream: TStream;
begin
  Stream := TFileStream.Create( AFileName, fmCreate );
  try
    SaveToStream( Stream );
  finally
    Stream.Free;
  end;
end;

procedure TNeuralNetwork.SaveToStream(const AStream: TStream);
var
  i: int32;
begin
  AStream.Write( FLayersCount, 4 );
  for I := 0 to FLayersCount1 do
    FLayers[ i ].SaveToStream( AStream );
end;

procedure TNeuralNetwork.SetLossFunction(const Value: TNNLosses);
begin
  if Assigned( FLossFunction ) and ( FLossFunction.FType = Value ) then exit;
  if Assigned( FLossFunction ) then FLossFunction.Free;
  FLossFunction := TNNLossesClassList[ Value ].Create;
end;

procedure TNeuralNetwork.Train( AEpochs, ASequences: int32; AGetDataProc: TNNGetTrainDataProc; AResultProc: TNNTrainResultProc );
var
  i, j: int32;
  _data, _yTrue: PNNFloat;
begin
  Build( true );
  Initialize;

  FLossFunction.Init;
  for I := 0 to FLayersCount1 do FLayers[ i ].FOptimizer.Init;

  Dec( ASequences );
  for I := 0 to AEpochs do begin
    for j := 0 to ASequences do begin
      AGetDataProc( self, i, j, _data, _yTrue );
      BackwardPropagation( _data, _yTrue );
      AResultProc( self, i, j, FLossFunction.MeanValue );
    end;
  end;
end;

{ TNNLayer }

constructor TNNLayer.Create;
begin
  FUseBiases := True;
end;

class function TNNLayer.CreateFromStream(const ANeuralNetwork: TObject;
  const AStream: TStream): TNNLayer;
var
  code: TNNLayerType;
begin
  AStream.Read( code, 4 );
  case code of
    ltFullyConnected: begin
      Result := TNNFullyConnectedLayer.Create;
      Result.LoadFromStream( AStream );
      exit;
    end;
  end;
  raise Exception.Create( 'Error Unknown Layer Pos=' + UIntToStr( AStream.Position - 1 ) );
end;

procedure TNNLayer.EmptyProcess; begin end;

{ TNNLossFunction }

constructor TNNLossFunction.Create(const ALossFunctionType: TNNLosses);
begin
  FType := ALossFunctionType;
  FName := TNNLosses_str[ FType ];
end;

constructor TNNLossFunction.Create;
begin

end;

procedure TNNLossFunction.Init;
begin

end;

{ TNNOptimizer }

constructor TNNOptimizer.Create(const AOptimizerOptimizerType: TNNOptimizerType;
  ALearningRate: NNFloat);
begin
  FType := AOptimizerOptimizerType;
  FName := TNNOptimizerType_str[ FType ];
  FLearningRate := ALearningRate;
end;

constructor TNNOptimizer.Create;
begin

end;

procedure TNNOptimizer.Init;
begin

end;

end.
